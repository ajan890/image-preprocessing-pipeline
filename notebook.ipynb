{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d852ee58",
   "metadata": {},
   "source": [
    "## load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d010ffc4",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-08-06T21:07:23.553873Z",
     "start_time": "2024-08-06T21:07:04.631010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:100% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from process_images import *\n",
    "from pystripe.core import *\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_images(img_list: List[ndarray], img_labels: List[str], vmax: int):\n",
    "    if len(img_list) == 1:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(img_list[0], cmap='gray', vmin=0, vmax=vmax)\n",
    "        plt.title(img_labels[0])\n",
    "    else:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=len(img_list), figsize=(20, 20))\n",
    "        for idx, (im, label) in enumerate(zip(img_list, img_labels)):\n",
    "            axes[idx].imshow(im, cmap='gray', vmin=0, vmax=vmax)\n",
    "            axes[idx].set_title(label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b5f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel_image_processor import *\n",
    "tsv_volume = TSVVolume.load(r'E:\\20230510_13_34_13_SM230308_05_LS_15x_800z_MIP_stitched\\Ex_488_Em_525_MIP_xml_import_step_5.xml')\n",
    "shape: Tuple[int, int, int] = tsv_volume.volume.shape  # shape is in z y x format\n",
    "img = tsv_volume.imread(\n",
    "    VExtent(\n",
    "        tsv_volume.volume.x0, tsv_volume.volume.x1,\n",
    "        tsv_volume.volume.y0, tsv_volume.volume.y1,\n",
    "        tsv_volume.volume.z0 + shape[0]//2, tsv_volume.volume.z0 + shape[0]//2 + 1),\n",
    "    tsv_volume.dtype)[0]\n",
    "parallel_image_processor(\n",
    "    source=TSVVolume.load(r'/data/20230419_17_34_03_SM221011_06_LS_15x_800z_stitched/Ex_488_Em_525_xml_import_step_5.xml'),\n",
    "    destination=r\"/data/20230419_17_34_03_SM221011_06_LS_15x_800z_stitched/Ex_488_Em_525_tif\",\n",
    "    fun=process_img,\n",
    "    kwargs={'bleach_correction_frequency': 0.0005, 'bleach_correction_max_method': False, 'bleach_correction_y_slice_max': None, 'threshold': None, 'sigma': (4000.0, 4000.0), 'bidirectional': True, 'lightsheet': False, 'percentile': 0.25, 'rotate': 90, 'convert_to_8bit': False, 'bit_shift_to_right': 8, 'tile_size': (39220, 28056), 'd_type': 'uint16', \"verbose\": True},\n",
    "    source_voxel=(0.8, 0.4, 0.4),\n",
    "    target_voxel=20,\n",
    "    max_processors=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_layer(\n",
    "    index: int,          # layer of image requested\n",
    "    image: ndarray,      # 3-D image (use TifStack.as_3d_numpy())\n",
    "    plane = \"xy\",        # must be \"xy\", \"yx\", \"xz\", \"zx\", \"yz\", \"zy\"\n",
    "    img_format = \"zyx\",  # xyz in some order\n",
    "):\n",
    "    # guards\n",
    "    if plane not in {\"xy\", \"yx\", \"xz\", \"zx\", \"yz\", \"zy\"} or img_format not in {\"zyx\", \"zxy\", \"yxz\", \"yzx\", \"xyz\", \"xzy\"}:\n",
    "        print(f\"Invalid plane selected in get_layer().  Plane: {plane}, Layer: {index}, Img_format: {img_format}\\nReturning to caller...\")\n",
    "        return None\n",
    "\n",
    "    # get the layer\n",
    "    if 'x' not in plane:   sub = img_format.index('x')\n",
    "    elif 'y' not in plane: sub = img_format.index('y')\n",
    "    elif 'z' not in plane: sub = img_format.index('z')\n",
    "\n",
    "    if sub == 0:   layer_image = image[index, :, :]\n",
    "    elif sub == 1: layer_image = image[:, index, :]\n",
    "    elif sub == 2: layer_image = image[:, :, index]\n",
    "\n",
    "    # if plane is flipped compared to image format, return the transpose.\n",
    "    if plane not in (img_format[:sub] + img_format[sub + 1:]):\n",
    "        return layer_image.transpose()\n",
    "    return layer_image\n",
    "\n",
    "# run to rotate images\n",
    "from os import makedirs\n",
    "\n",
    "######## CHANGE THESE ########\n",
    "cha1_path = \"D:/BMAP/Brain 4/cha1\"\n",
    "cha2_path = \"D:/BMAP/Brain 4/cha2\"\n",
    "cha3_path = \"D:/BMAP/Brain 4/cha3\"\n",
    "# set to None if nothing to convert\n",
    "\n",
    "##############################\n",
    "if cha1_path:\n",
    "    makedirs(cha1_path + \"_zx\", exist_ok=True)\n",
    "    makedirs(cha1_path + \"_zy\", exist_ok=True)\n",
    "    stack1 = TifStack(cha1_path).as_3d_numpy()\n",
    "    for i in range(stack1.shape[1]):\n",
    "        imwrite(cha1_path + \"_zx/\" + str(i + 1) + \".tif\", get_layer(i, stack1, \"zx\"))\n",
    "    for i in range(stack1.shape[2]):\n",
    "        imwrite(cha1_path + \"_zy/\" + str(i + 1) + \".tif\", get_layer(i, stack1, \"zy\"))\n",
    "if cha2_path:\n",
    "    makedirs(cha2_path + \"_zx\", exist_ok=True)\n",
    "    makedirs(cha2_path + \"_zy\", exist_ok=True)\n",
    "    stack2 = TifStack(cha2_path).as_3d_numpy()\n",
    "    for i in range(stack2.shape[1]):\n",
    "        imwrite(cha2_path + \"_zx/\" + str(i + 1) + \".tif\", get_layer(i, stack2, \"zx\"))\n",
    "    for i in range(stack2.shape[2]):\n",
    "        imwrite(cha2_path + \"_zy/\" + str(i + 1) + \".tif\", get_layer(i, stack2, \"zy\"))\n",
    "if cha3_path:\n",
    "    makedirs(cha3_path + \"_zx\", exist_ok=True)\n",
    "    makedirs(cha3_path + \"_zy\", exist_ok=True)\n",
    "    stack3 = TifStack(cha3_path).as_3d_numpy()\n",
    "    for i in range(stack3.shape[1]):\n",
    "        imwrite(cha3_path + \"_zx/\" + str(i + 1) + \".tif\", get_layer(i, stack3, \"zx\"))\n",
    "    for i in range(stack3.shape[2]):\n",
    "        imwrite(cha3_path + \"_zy/\" + str(i + 1) + \".tif\", get_layer(i, stack3, \"zy\"))\n",
    "print(\"Operation Completed\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca378246fb1df6fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_data(file_path:str, title:str, label1:str, label2:str):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        line = file.readline()\n",
    "\n",
    "        x_offset = [0]\n",
    "        y_offset = [0]\n",
    "\n",
    "        while line:\n",
    "            if \"Skipped\" in line:\n",
    "                x_offset.append(0)\n",
    "                y_offset.append(0)\n",
    "                line = file.readline()\n",
    "                continue\n",
    "            s = line.split(\",\")\n",
    "            x_offset.append(float(s[-2][:-1]))\n",
    "            line = file.readline()\n",
    "            s = line.split(\",\")\n",
    "            y_offset.append(float(s[-2][:-1]))\n",
    "            line = file.readline()\n",
    "            # skip last line\n",
    "            line = file.readline()\n",
    "\n",
    "        plt.plot(range(len(x_offset)), x_offset, label=label1)\n",
    "        plt.plot(range(len(y_offset)), y_offset, label=label2)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Layer index\")\n",
    "        plt.ylabel(\"Units\")\n",
    "        plt.ylim((-20, 20))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zy_matrices_im12.txt\", \"Image alignment offsets of Images 1 and 2 from zy-slices\", \"z-offset\", \"y-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zy_matrices_im13.txt\", \"Image alignment offsets of Images 1 and 3 from zy-slices\", \"z-offset\", \"y-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zx_matrices_im12.txt\", \"Image alignment offsets of Images 1 and 2 from zx-slices\", \"z-offset\", \"x-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/zx_matrices_im13.txt\", \"Image alignment offsets of Images 1 and 3 from zx-slices\", \"z-offset\", \"x-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/xy_matrices_im12.txt\", \"Image alignment offsets of Images 1 and 2 from xy-slices\", \"x-offset\", \"y-offset\")\n",
    "plot_data(\"D:/BMAP/Brain 4/offsets/xy_matrices_im13.txt\", \"Image alignment offsets of Images 1 and 3 from xy-slices\", \"x-offset\", \"y-offset\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41eb0adc7da12597"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from align_images import get_layer\n",
    "from numpy import min, max, uint8, zeros_like, ndarray, multiply\n",
    "\n",
    "def write_to_file(images: list[ndarray], filepath: Path):\n",
    "    filepath.mkdir(parents=True, exist_ok=True)\n",
    "    for n, image in enumerate(images):\n",
    "        local = filepath / f'cha{n}'\n",
    "        local.mkdir(parents=True, exist_ok=True)\n",
    "        for layer in range(image.shape[0]):\n",
    "            path = local.absolute() / (str(layer) + \".tif\")\n",
    "            imwrite(path, get_layer(layer, image, \"yx\"))\n",
    "        print(\"wrote to file\")\n",
    "        \n",
    "# written by ChatGPT\n",
    "def normalize_array_inplace(arr: ndarray):\n",
    "    min_val = min(arr)\n",
    "    max_val = max(arr)\n",
    "\n",
    "    arr -= min_val\n",
    "    arr /= (max_val - min_val)\n",
    "\n",
    "    # Scale the values to be between 0 and 255\n",
    "    arr *= 255\n",
    "    arr.astype(uint8, copy=False)\n",
    "    \n",
    "\n",
    "# multiplies two 2d-ndarrays, saving solution in arr1 instead of allocating more memory\n",
    "def mult_in_place(arr1, arr2):\n",
    "    for r in range(arr1.shape[0]):\n",
    "        for c in range(arr1.shape[1]):\n",
    "            arr1[r][c] *= arr2[r][c]\n",
    " \n",
    " \n",
    "def get_borders(img: ndarray, copy=False):\n",
    "    print(\"get_borders\")\n",
    "    mask = zeros_like(img)\n",
    "    for ind in range(img.shape[0]):\n",
    "        print(f'layer {ind}')\n",
    "        mask[ind] = get_img_mask(img[ind], otsu_threshold(img[ind]))\n",
    "    multiply(img, mask, out=img)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T10:23:55.378275Z",
     "start_time": "2024-04-07T10:23:55.367145Z"
    }
   },
   "id": "55e7781013179a5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from align_images import align_all_images, resize_arrays, get_borders\n",
    "from supplements.tifstack import TifStack\n",
    "\n",
    "cha1 = TifStack(\"C:/Users/ajan/Pictures/cha0\").as_3d_numpy()\n",
    "cha2 = TifStack(\"C:/Users/ajan/Pictures/cha1\").as_3d_numpy()\n",
    "cha3 = TifStack(\"C:/Users/ajan/Pictures/cha2\").as_3d_numpy()\n",
    "output_path = Path(\"D:/aligned_images/align_test\")\n",
    "max_iterations = 50\n",
    "\n",
    "print(\"Images loaded\")\n",
    "\n",
    "# make arrays the same size\n",
    "channels = resize_arrays([cha1, cha2, cha3])\n",
    "\n",
    "print(\"Images resized\")\n",
    "# print(\"test\")\n",
    "# for i in channels: print(i.shape)\n",
    "\n",
    "\n",
    "for img in channels:\n",
    "    get_borders(img)    \n",
    "\n",
    "print(\"got borders\")\n",
    "\n",
    "# align images\n",
    "alignments, residuals = align_all_images(channels, verbose=True, make_copy=False)\n",
    "\n",
    "# normalize images and convert to uint8\n",
    "for channel in channels: normalize_array_inplace(channel)\n",
    "\n",
    "print(\"Images normalized\")\n",
    "\n",
    "write_to_file(channels, output_path)\n",
    "\n",
    "print(\"Done!\")\n",
    "# print(\"Alignment: \", end='')\n",
    "# print(alignments)\n",
    "# print(\"Residuals: \", end='')\n",
    "# print(residuals) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafb1ca8333bf16a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f2a05a73a6b34fd3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "* try using mask for better edge detection\n",
    "* Sobel operator -> mask -> align"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e79bf833d8864b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert stacks to .ims\n",
    "import os\n",
    "dir_name = \"D:/aligned_images/20230825_SM230601_06_LS_15x_800z_B6/orig_aligned\"\n",
    "\n",
    "os.system(f'python convert.py -i \"{dir_name}/cha0\" -o \"{dir_name}/cha0.ims\" -dx 10 -dy 10 -dz 10')\n",
    "os.system(f'python convert.py -i \"{dir_name}/cha1\" -o \"{dir_name}/cha1.ims\" -dx 10 -dy 10 -dz 10')\n",
    "os.system(f'python convert.py -i \"{dir_name}/cha2\" -o \"{dir_name}/cha2.ims\" -dx 10 -dy 10 -dz 10')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T22:30:28.289576Z",
     "start_time": "2024-04-20T22:29:36.947419Z"
    }
   },
   "id": "61e722e183934ca5",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!python align_images.py C:/Users/ajan/Pictures/ D:\\aligned_images\\align_test\n",
    "!echo done"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8963c480679dfe04",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from align_images import resize_arrays\n",
    "\n",
    "from os import system\n",
    "from matplotlib.pyplot import imshow, show\n",
    "\n",
    "pad_only = False\n",
    "generate_ims = False\n",
    "dx, dy, dz = 0, 0, 0\n",
    "filepaths = [\"C:/Users/ajan/Pictures/cha0\", \"C:/Users/ajan/Pictures/cha1\",\"C:/Users/ajan/Pictures/cha2\"]\n",
    "output_file = f\"C:/Users/ajan/Pictures/align_test\"\n",
    "# Image Processing --------------------------------------------------------------------\n",
    "print(\"Loading images...\")\n",
    "count = 0\n",
    "try:\n",
    "    cha1 = TifStack(filepaths[0]).as_3d_numpy()\n",
    "    count = 1\n",
    "    cha2 = TifStack(filepaths[1]).as_3d_numpy()\n",
    "    count = 2\n",
    "    cha3 = TifStack(filepaths[2]).as_3d_numpy()\n",
    "    print(\"Images loaded\")\n",
    "except Exception:\n",
    "    print(f\"Error: Invalid TifStack found at {filepaths[count]}\")\n",
    "    exit(1)\n",
    "\n",
    "output_path = Path(output_file)\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(filepaths)\n",
    "\n",
    "imshow(cha1[0])\n",
    "show(block=True)\n",
    "imshow(cha2[0])\n",
    "show(block=True)\n",
    "imshow(cha3[0])\n",
    "show(block=True)\n",
    "\n",
    "print(\"Resizing images...\")\n",
    "\n",
    "channels = resize_arrays([cha1, cha2, cha3])\n",
    "print(\"Images resized\")\n",
    "\n",
    "# normalize images and convert to uint8\n",
    "# print(\"Normalizing images\")\n",
    "# for channel in channels: normalize_array_inplace(channel)\n",
    "\n",
    "\n",
    "\n",
    "if not pad_only:\n",
    "    print(\"Aligning images... (this may take a while)\")\n",
    "    # TODO: FIX THIS\n",
    "    for i in range(len(channels)):\n",
    "        # channels[i] *= (channels[i] > percentile(channels[i], 80))  # set all pixels below threshold to zero. (weeds out noise along edges)\n",
    "        # get_borders(channels[i])\n",
    "        # channels[i] = sobel(channels[i])\n",
    "\n",
    "        print(channels[i])\n",
    "        imshow(channels[i][0, :, :])\n",
    "        show()\n",
    "\n",
    "\n",
    "    # # align images\n",
    "    # alignments, residuals = align_all_images(channels, max_iter=max_iterations, verbose=False, make_copy=False)\n",
    "    # print(\"Images aligned\")\n",
    "\n",
    "\n",
    "print(\"Images normalized\")\n",
    "\n",
    "print(\"Writing to file\")\n",
    "write_to_file(channels, output_path)\n",
    "print(\"Wrote to file\")\n",
    "\n",
    "if generate_ims:\n",
    "    print(\"Generating .ims files\")\n",
    "    system(f'python convert.py -i \"{output_path}/cha0\" -o \"{output_path}/cha0.ims\" -dx {dx} -dy {dy} -dz {dz}')\n",
    "    system(f'python convert.py -i \"{output_path}/cha1\" -o \"{output_path}/cha1.ims\" -dx {dx} -dy {dy} -dz {dz}')\n",
    "    system(f'python convert.py -i \"{output_path}/cha2\" -o \"{output_path}/cha2.ims\" -dx {dx} -dy {dy} -dz {dz}')\n",
    "    print(\".ims files created\")\n",
    "\n",
    "print(\"Alignments:\")\n",
    "# print(alignments)\n",
    "print(\"\\n\\nOperation completed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T06:03:48.759589Z",
     "start_time": "2024-04-19T06:03:48.484374Z"
    }
   },
   "id": "2177828f419278c9",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid data type provided!  Writing to file with uint8.\n",
      "wrote to file\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, ones, pad, uint8\n",
    "from align_images import write_to_file, roll_pad\n",
    "from pathlib import Path\n",
    "\n",
    "cube = zeros((126, 126, 126), dtype=uint8)\n",
    "cube = pad(cube, 1, mode='constant', constant_values=255)\n",
    "\n",
    "cha0 = pad(cube, 64)\n",
    "cha1 = pad(cube, 64)\n",
    "cha2 = pad(cube, 64)\n",
    "\n",
    "roll_pad(cha1, 1, axis=0)\n",
    "roll_pad(cha1, 2, axis=1)\n",
    "roll_pad(cha1, 3, axis=2)\n",
    "\n",
    "roll_pad(cha2, -3, axis=0)\n",
    "roll_pad(cha2, -2, axis=1)\n",
    "roll_pad(cha2, -1, axis=2)\n",
    "\n",
    "\n",
    "path = Path(\"D:/aligned_images/cube_test/upright_borders\")\n",
    "\n",
    "write_to_file([cha0, cha1, cha2], path, data_type='uint8', verbose=True)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T05:51:37.741574Z",
     "start_time": "2024-05-13T05:51:35.214050Z"
    }
   },
   "id": "52591132972ab1c2",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from process_images import *\n",
    "from pystripe.core import *\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "from numpy import vectorize, amax, amin\n",
    "from copy import deepcopy\n",
    "def plot_images(img_list: List[ndarray], img_labels: List[str], vmax: int):\n",
    "    if len(img_list) == 1:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(img_list[0], cmap='gray', vmin=0, vmax=vmax)\n",
    "        plt.title(img_labels[0])\n",
    "    else:\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=len(img_list), figsize=(20, 20))\n",
    "        for idx, (im, label) in enumerate(zip(img_list, img_labels)):\n",
    "            axes[idx].imshow(im, cmap='gray', vmin=0, vmax=vmax)\n",
    "            axes[idx].set_title(label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 255 / (1 + exp(-10* x))\n",
    "\n",
    "v_sigmoid = vectorize(sigmoid)\n",
    "img = imread_tif_raw_png(Path(r\"D:\\aligned_images\\20230825_SM230601_06_LS_15x_800z_B6\\orig\\cha0\\111.tif\"))\n",
    "sobel_img = sobel(img)\n",
    "print(\"Max: \", amax(sobel_img))\n",
    "print(\"Min: \", amin(sobel_img))\n",
    "\n",
    "threshold = threshold_multiotsu(sobel_img, classes=4)[2]\n",
    "s_img = v_sigmoid(sobel_img)\n",
    "\n",
    "mask = get_img_mask(s_img, threshold, close_steps=50, open_steps=5, flood_fill_flag=4)\n",
    "plot_images([img, sobel_img, mask], [\"orig\", \"sobel\", \"mask\"], threshold)  # mask*threshold"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75386edb1bfb109d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "from align_images import roll_pad\n",
    "from pathlib import Path  \n",
    "from tifffile import natural_sorted, imread, imwrite\n",
    "from numpy import zeros\n",
    "\n",
    "def shift_big_image(file_path_input: Path, file_path_output: Path, offset: int, axis): # (axis 0 = z, axis 1 = y, axis 2 = x)\n",
    "    if offset == 0: return\n",
    "    file_path_output.mkdir(parents=True, exist_ok=True)\n",
    "    files = natural_sorted([file.__str__() for file in file_path_input.iterdir() if\n",
    "                      file.is_file() and file.suffix.lower() in (\".tif\", \".tiff\")])\n",
    "    first_file = imread(files[0])\n",
    "    \n",
    "    file_shape = first_file.shape\n",
    "    data_type = first_file.dtype\n",
    "    num_files = len(files)\n",
    "    \n",
    "    layer_num = 0\n",
    "    \n",
    "    print(file_shape)\n",
    "    \n",
    "    if axis == 0: # z-axis\n",
    "        if offset > 0:\n",
    "            # front padding\n",
    "            while layer_num < offset:\n",
    "                output_file = file_path_output / f\"{layer_num}.tif\"\n",
    "                imwrite(output_file, zeros(file_shape, dtype=data_type), dtype=data_type)\n",
    "                layer_num += 1\n",
    "            # rest of the files\n",
    "            input_layer = 0\n",
    "            while layer_num < num_files:\n",
    "                output_file = file_path_output / f\"{layer_num}.tif\"\n",
    "                temp_file = imread(files[input_layer])\n",
    "                imwrite(output_file, temp_file, dtype=data_type)\n",
    "                layer_num += 1\n",
    "                input_layer += 1\n",
    "        else:\n",
    "            # files\n",
    "            input_layer = -offset\n",
    "            while layer_num < num_files + offset:\n",
    "                output_file = file_path_output / f\"{layer_num}.tif\"\n",
    "                temp_file = imread(files[input_layer])\n",
    "                imwrite(output_file, temp_file, dtype=data_type)\n",
    "                layer_num += 1\n",
    "                input_layer += 1\n",
    "            # padding\n",
    "            while layer_num < num_files:\n",
    "                output_file = file_path_output / f\"{layer_num}.tif\"\n",
    "                imwrite(output_file, zeros(file_shape, dtype=data_type), dtype=data_type)\n",
    "                layer_num += 1\n",
    "    else:\n",
    "        for layer_num, file in enumerate(files):\n",
    "            output_file = file_path_output / f\"{layer_num}.tif\"\n",
    "            temp_file = imread(file)\n",
    "            roll_pad(temp_file, offset, axis - 1)\n",
    "            imwrite(output_file, temp_file, dtype=data_type)\n",
    "            \n",
    "            \n",
    "shift_big_image(Path(r'D:\\aligned_images\\cube_test\\upright_borders\\cha0'), Path(r'D:\\aligned_images\\cube_test\\upright_borders\\shift_test\\cha0'), -50, 2)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T06:19:13.271195Z",
     "start_time": "2024-05-13T06:19:12.212994Z"
    }
   },
   "id": "6bb4dffb353dc7af",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# converts original to downsampled\n",
    "# !python convert.py --input D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\Ex_488_Em_525_tif --tif D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\downsampled\\Ex_488_Em_525_tif --downsample_path D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\downsampled\\Ex_488_Em_525_tif -dsx 10 -dsy 10 -dsdt uint8 -dx 2 -dy 2 -dz 2 -dt 20\n",
    "# !python convert.py --input D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\Ex_561_Em_600_tif --tif D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\downsampled\\Ex_561_Em_600_tif --downsample_path D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\downsampled\\Ex_561_Em_600_tif -dsx 10 -dsy 10 -dsdt uint8 -dx 2 -dy 2 -dz 2 -dt 20\n",
    "!python convert.py --input D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\Ex_642_Em_680_tif --tif D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\downsampled\\Ex_642_Em_680_tif --downsample_path D:\\aligned_images\\20220622_SW220414_02_LS_6x_1000z\\downsampled\\Ex_642_Em_680_tif -dsx 10 -dsy 10 -dsdt uint8 -dx 2 -dy 2 -dz 2 -dt 20"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a60ccb2b6054dfcb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x max: 16000.000000000\n",
      "x min: 0.000000000\n",
      "y max: 0.000000000\n",
      "y min: -16000.000000000\n",
      "z max: 0.000000000\n",
      "z min: -16000.000000000\n",
      "Description: [b'(' b'd' b'e' b's' b'c' b'r' b'i' b'p' b't' b'i' b'o' b'n' b' ' b'n'\n",
      " b'o' b't' b' ' b's' b'p' b'e' b'c' b'i' b'f' b'i' b'e' b'd' b')']\n",
      "ExtMax0: [b'1' b'6' b'0' b'0' b'0' b'.' b'0' b'0' b'0' b'0' b'0' b'0' b'0' b'0'\n",
      " b'0']\n",
      "ExtMax1: [b'0' b'.' b'0' b'0' b'0' b'0' b'0' b'0' b'0' b'0' b'0']\n",
      "ExtMax2: [b'0' b'.' b'0' b'0' b'0' b'0' b'0' b'0' b'0' b'0' b'0']\n",
      "ExtMin0: [b'0' b'.' b'0' b'0' b'0' b'0' b'0' b'0' b'0' b'0' b'0']\n",
      "ExtMin1: [b'-' b'1' b'6' b'0' b'0' b'0' b'.' b'0' b'0' b'0' b'0' b'0' b'0' b'0'\n",
      " b'0' b'0']\n",
      "ExtMin2: [b'-' b'1' b'6' b'0' b'0' b'0' b'.' b'0' b'0' b'0' b'0' b'0' b'0' b'0'\n",
      " b'0' b'0']\n",
      "Name: [b'(' b'n' b'a' b'm' b'e' b' ' b'n' b'o' b't' b' ' b's' b'p' b'e' b'c'\n",
      " b'i' b'f' b'i' b'e' b'd' b')']\n",
      "OriginalFormat: [b'T' b'I' b'F' b'F']\n",
      "OriginalFormatFileIOVersion: [b'I' b'm' b'a' b'r' b'i' b's' b'F' b'i' b'l' b'e' b'I' b'O' b' ' b'x'\n",
      " b'6' b'4' b' ' b'9' b'.' b'8' b'.' b'0']\n",
      "RecordingDate: [b'2' b'0' b'2' b'4' b'-' b'0' b'5' b'-' b'2' b'4' b' ' b'0' b'6' b':'\n",
      " b'0' b'6' b':' b'3' b'2']\n",
      "ResampleDimensionX: [b't' b'r' b'u' b'e']\n",
      "ResampleDimensionY: [b't' b'r' b'u' b'e']\n",
      "ResampleDimensionZ: [b't' b'r' b'u' b'e']\n",
      "Unit: [b'u' b'm']\n",
      "X: [b'8' b'0' b'0' b'0']\n",
      "Y: [b'8' b'0' b'0' b'0']\n",
      "Z: [b'8' b'0' b'0' b'0']\n"
     ]
    }
   ],
   "source": [
    "# h5py testing\n",
    "import h5py\n",
    "\n",
    "# def print_hdf5_structure(name, obj):\n",
    "#     if isinstance(obj, h5py.Group):\n",
    "#         print(f\"Group: {name}\")\n",
    "#     elif isinstance(obj, h5py.Dataset):\n",
    "#         print(f\"Dataset: {name}\")\n",
    "# \n",
    "# def print_all_groups_and_datasets(file_path):\n",
    "#     with h5py.File(file_path, 'r') as file:\n",
    "#         file.visititems(print_hdf5_structure)\n",
    "\n",
    "def combine_bytes(lst):\n",
    "    return ''.join(byte.decode('utf-8') for byte in lst)\n",
    "\n",
    "\n",
    "image_path = r'D:\\aligned_images\\cube_test\\big_cube\\cha0.ims'\n",
    "\n",
    "# file = h5py.File(image_path)\n",
    "# images = file[f\"DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Data\"]\n",
    "\n",
    "# print_all_groups_and_datasets(image_path)\n",
    "\n",
    "file = h5py.File(image_path)\n",
    "attrs = file[f\"DataSetInfo/Image\"].attrs\n",
    "\n",
    "x_max = combine_bytes(attrs['ExtMax0'])\n",
    "x_min = combine_bytes(attrs['ExtMin0'])\n",
    "y_max = combine_bytes(attrs['ExtMax1'])\n",
    "y_min = combine_bytes(attrs['ExtMin1'])\n",
    "z_max = combine_bytes(attrs['ExtMax2'])\n",
    "z_min = combine_bytes(attrs['ExtMin2'])\n",
    "\n",
    "print(f\"x max: {x_max}\")\n",
    "print(f\"x min: {x_min}\")\n",
    "print(f\"y max: {y_max}\")\n",
    "print(f\"y min: {y_min}\")\n",
    "print(f\"z max: {z_max}\")\n",
    "print(f\"z min: {z_min}\")\n",
    "\n",
    "\n",
    "for k, v in attrs.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-06T23:44:51.596812Z",
     "start_time": "2024-08-06T23:44:51.581921Z"
    }
   },
   "id": "aa9b3266091446da",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Group: DataSet\n",
    "Group: DataSet/ResolutionLevel 0\n",
    "Group: DataSet/ResolutionLevel 0/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 0/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 0/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSet/ResolutionLevel 1\n",
    "Group: DataSet/ResolutionLevel 1/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 1/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 1/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 1/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSet/ResolutionLevel 2\n",
    "Group: DataSet/ResolutionLevel 2/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 2/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 2/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 2/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSet/ResolutionLevel 3\n",
    "Group: DataSet/ResolutionLevel 3/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 3/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 3/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 3/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSet/ResolutionLevel 4\n",
    "Group: DataSet/ResolutionLevel 4/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 4/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 4/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 4/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSet/ResolutionLevel 5\n",
    "Group: DataSet/ResolutionLevel 5/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 5/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 5/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 5/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSet/ResolutionLevel 6\n",
    "Group: DataSet/ResolutionLevel 6/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 6/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 6/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 6/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSet/ResolutionLevel 7\n",
    "Group: DataSet/ResolutionLevel 7/TimePoint 0\n",
    "Group: DataSet/ResolutionLevel 7/TimePoint 0/Channel 0\n",
    "Dataset: DataSet/ResolutionLevel 7/TimePoint 0/Channel 0/Data\n",
    "Dataset: DataSet/ResolutionLevel 7/TimePoint 0/Channel 0/Histogram\n",
    "Group: DataSetInfo\n",
    "Group: DataSetInfo/Channel 0\n",
    "Group: DataSetInfo/Image\n",
    "Group: DataSetInfo/Imaris\n",
    "Group: DataSetInfo/ImarisDataSet\n",
    "Group: DataSetInfo/Log\n",
    "Group: DataSetInfo/TimeInfo\n",
    "Group: Thumbnail\n",
    "Dataset: Thumbnail/Data\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1614a9784a32964"
  }
  ]
  
  
  
  
 , "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
